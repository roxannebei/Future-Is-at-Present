{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dV6GrgrJLZqW",
    "outputId": "ae5bb696-682d-4797-dc29-3103bd75546f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, Reshape, BatchNormalization, LeakyReLU, Conv2DTranspose\n",
    "from keras.layers import Flatten, Reshape, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import skimage\n",
    "import imutils\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGhBWWQsQXZ1",
    "outputId": "eb0e696b-0040-4e5b-a713-edbd9375d60e"
   },
   "outputs": [],
   "source": [
    "data = np.load(\"/content/drive/MyDrive/stats402_data/human_envolving_colored_data_large_R_channel.npy\")\n",
    "frame_num = data.shape[0]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "kUE6Acn6QkPk",
    "outputId": "491016d3-13eb-4020-a696-d93466531688"
   },
   "outputs": [],
   "source": [
    "# show some sample frames\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "a, b =3, 4\n",
    "for i in range(11):  \n",
    "    plt.subplot(a, b, i+1)\n",
    "    image = data[350*i]\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title('frame: ' + str(350*i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UubARlR0QdPR",
    "outputId": "7d03b8ed-f38d-41e3-cf7b-620e49f2b2c6"
   },
   "outputs": [],
   "source": [
    "# split the training and testing data\n",
    "threshold_1 = 3500\n",
    "x_train = data[0:threshold_1]\n",
    "\n",
    "# convert to float in [0,1]\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLSzqhP2Qwj7"
   },
   "outputs": [],
   "source": [
    "# function which samples a new point in the latent space based on the encoder result\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZL6ysJW1QyUv",
    "outputId": "51639343-e34f-46a1-b6ee-08e2147ad7cc"
   },
   "outputs": [],
   "source": [
    "# building the encoder\n",
    "latent_space = 8\n",
    "\n",
    "inputs = Input(shape=[x_train.shape[1], x_train.shape[2], 1])\n",
    "\n",
    "z = Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation=\"selu\")(inputs)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU()(z)\n",
    "z = Conv2D(filters=32, kernel_size=4, strides=2, padding='same', activation=\"selu\")(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU()(z)\n",
    "z = Conv2D(filters=16, kernel_size=4, strides=2, padding='same', activation=\"selu\")(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU()(z)\n",
    "z = Flatten()(z)\n",
    "\n",
    "\n",
    "# the encoder network has two outputs which are the parameters for Gaussian distribution \n",
    "# in the Sampling function\n",
    "\n",
    "codings_mean = Dense(latent_space)(z)\n",
    "codings_log_var = Dense(latent_space)(z)\n",
    "\n",
    "# use the Sampling function to obtain the point 'codings' in the latent space\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "encoder = Model(inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "628Tkl1SQ01M",
    "outputId": "b2d8c3d8-cbd8-45e9-e5a1-89c8f9b2c1ac"
   },
   "outputs": [],
   "source": [
    "# the decoder mirrors the encoder\n",
    "\n",
    "decoder_inputs = Input(shape=[latent_space])\n",
    "\n",
    "x = Reshape([-1, 2, 2])(decoder_inputs)\n",
    "x = Conv2DTranspose(filters=16, kernel_size=4, strides=1, padding='same', activation=\"selu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2DTranspose(filters=32, kernel_size=4, strides=1, padding='same', activation=\"selu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same', activation=\"selu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(x_train.shape[1] * x_train.shape[2], activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([x_train.shape[1], x_train.shape[2], 1])(x)\n",
    "\n",
    "decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drtupCOVQ25j"
   },
   "outputs": [],
   "source": [
    "# combine the encoder and decoder to the variational autoencoder\n",
    "# only codings, the sampled point in latent space, is passed through\n",
    "_, _, codings = encoder(inputs)\n",
    "reconstructions = decoder(codings)\n",
    "encoder_decoder = keras.Model(inputs=[inputs], outputs=[reconstructions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzbXVevSQ43D",
    "outputId": "c6ffef44-33eb-4358-cd8d-60c16e9bd35a"
   },
   "outputs": [],
   "source": [
    "# we need to add the Kullback Leibler divergence to the loss function\n",
    "latent_loss = -0.5 * K.sum(1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean), axis=-1)\n",
    "encoder_decoder.add_loss(K.mean(latent_loss) / 9216.)\n",
    "\n",
    "# built the model\n",
    "encoder_decoder.compile(loss='binary_crossentropy', optimizer=keras.optimizers.RMSprop(clipnorm=0.0001))\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d-kQT-bQ6fT",
    "outputId": "a564dddf-f645-422d-97cc-e6e5b45b7ce0"
   },
   "outputs": [],
   "source": [
    "history = encoder_decoder.fit(x_train, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "eOjZSksEQ9F7",
    "outputId": "20ba5efc-3b7d-443e-fdaf-16d32410dc77"
   },
   "outputs": [],
   "source": [
    "# show the learning process\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs, loss, 'bo', label='Training')\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.legend()\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vzion4DnT0fS",
    "outputId": "2eceafe6-9675-4d82-db52-8de5fb4ca0ca"
   },
   "outputs": [],
   "source": [
    "# First, for comparison with the autoencoder example we simply feed random twodimensional vectors into the decoder.\n",
    "\n",
    "random = np.random.uniform(-0.5, 0.5, latent_space*10)\n",
    "random = random.reshape(10, latent_space)       # reshape to ten vectors\n",
    "random_img = decoder.predict(random) # make predictions for those vectors\n",
    "\n",
    "plt.figure(figsize=(10, 30))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(10, 1, i + 1)\n",
    "    plt.imshow(np.reshape(random_img[i], (x_train.shape[1], x_train.shape[2])), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4O0y8mOT6An"
   },
   "outputs": [],
   "source": [
    "def reconstruct(sample):\n",
    "    sample_reshape = np.reshape(sample, (1, sample.shape[0], sample.shape[1]))\n",
    "    z_mean, _, _ = encoder.predict(sample_reshape)\n",
    "    reconstruction = decoder.predict(z_mean)\n",
    "    reconstruction = np.reshape(reconstruction, (reconstruction.shape[1], reconstruction.shape[2]))\n",
    "    return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5UXAqyutT-Lp",
    "outputId": "23403f70-0036-4bf1-96f5-c24beb4bba9b"
   },
   "outputs": [],
   "source": [
    "# show some reconstruction result\n",
    "interval = 350\n",
    "\n",
    "plt.figure(figsize=(10,60))\n",
    "for i in range(11):\n",
    "\n",
    "    sample = data[i * interval]\n",
    "\n",
    "    sample = sample.astype('float32') / 255.0\n",
    "\n",
    "    plt.subplot(11, 2, 2*i+1)\n",
    "    plt.imshow((reconstruct(sample) * 255).astype('uint8'), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"reconstruction\")\n",
    "\n",
    "    plt.subplot(11, 2, 2*i+2)\n",
    "    plt.imshow((sample * 255).astype('uint8'), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"ground truth\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PRzRmky8UAyq",
    "outputId": "c2319fdc-b721-4ae1-9d10-dcd818d76a79"
   },
   "outputs": [],
   "source": [
    "# plot the latent space representation versus time\n",
    "\n",
    "z_mean, _, _ = encoder.predict(x_train)\n",
    "\n",
    "x = np.arange(z_mean.shape[0])\n",
    "\n",
    "plt.figure(figsize=(12, 20))\n",
    "\n",
    "for i in range(8):\n",
    "    plt.subplot(8, 1, i+1)\n",
    "    plt.plot(x, z_mean[:, i], \"b\")\n",
    "    plt.xlabel(\"time\", size = 14)\n",
    "    plt.ylabel(\"component #\" + str(i+1), size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUOmjyCgZLrG"
   },
   "outputs": [],
   "source": [
    "# save the trained model to file\n",
    "decoder.save(\"/content/drive/MyDrive/stats402_data/gray_decoder_evolution_B_channel\", save_format=\"h5\")\n",
    "decoder.save_weights(\"/content/drive/MyDrive/stats402_data/decoder_gray_model_evolution_B_channel_weights.h5\")\n",
    "\n",
    "# save the latent space representation to npy file\n",
    "time_series = np.arange(0, z_mean.shape[0])\n",
    "time_series = np.reshape(time_series, (z_mean.shape[0], 1))\n",
    "latent_representation = np.concatenate((time_series, z_mean), axis=1)\n",
    "print(latent_representation.shape)\n",
    "np.save(\"/content/drive/MyDrive/stats402_data/latent_space_representation_evolution_R_channel.npy\", latent_representation)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VAE_single_dim_large.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
